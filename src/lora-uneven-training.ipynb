{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2INOXSFL9vte",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "!pip install torch -q\n",
    "!pip install torchvision -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bSDTu4h97TFF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# False if you have already created and saved a .pth file to PTH_SAVE_PATH\n",
    "CREATE_NEW_DATASET = True\n",
    "\n",
    "# train, test, val set size. Should sum to 1\n",
    "SET_SIZES = {\n",
    "    \"train\": 0.8,\n",
    "    \"test\": 0.1,\n",
    "    \"val\": 0.1,\n",
    "}\n",
    "\n",
    "# samples per class in uniform dataset\n",
    "N_SAMPLES = 400\n",
    "\n",
    "# path to dataset (do not change)\n",
    "HM_DATA_PATH = \"../dataset/\"\n",
    "\n",
    "# path to pth saves (do not change)\n",
    "PTH_SAVE_PATH = \"../pth/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpJXUgcT97sz"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zPOBAjDlInvv",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds-proj/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daghjelm/Documents/kth/ds-proj/DD2430_Project/src\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random, importlib, transformers, itertools, copy\n",
    "import numpy as np, torch.nn as nn, torch, seaborn as sns, matplotlib.pyplot as plt, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "print(os.getcwd())# Our own files\n",
    "# sys.path.append('./src/')\n",
    "import model_functions, utils, training, datasets\n",
    "def set_seed(seed):# reproducable\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update():# if you change our files\n",
    "    import model_functions, utils, training, datasets\n",
    "    for lib in [model_functions, utils, training, datasets]:\n",
    "        importlib.reload(lib)# issues with not updating\n",
    "update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou5QvXmt3_Kr",
    "outputId": "ee73a633-1d13-47ed-86e3-640c1a03e48d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available(): # For apple silicon\n",
    "    device = 'mps'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/clip/processing_clip.py:149: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = transformers.CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = transformers.CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor.feature_extractor.do_rescale = False # make sure image values: False=> [0-1] and True=> [0,255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdQe6TDNGX4K",
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Full dataset, run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knitwear\n",
      "105099\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(HM_DATA_PATH+'articles_filtered.csv')\n",
    "embs = torch.load(HM_DATA_PATH+'embedds.pth', weights_only=True) # all 100k embeddings\n",
    "labs = torch.load(HM_DATA_PATH+'labels.pth', weights_only=True).tolist() #  100k labels\n",
    "hmd = datasets.HMDatasetDuplicates(embs, np.array(labs), df)\n",
    "print(hmd.article_id2suclass(694805002, 'garment_group_name'))\n",
    "#print(hmd.list_article_id2suclass(labs, 'garment_group_name'))#all\n",
    "print(len(labs))\n",
    "BALANCED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47071 Train size: 37656, Val size: 4707, Test size: 4708\n",
      "105099\n",
      "This should be empty set() set()\n",
      "The resulting sizes 84126 4707 4708\n"
     ]
    }
   ],
   "source": [
    "update()\n",
    "batch_size = 64\n",
    "set_sizes = {\"train\": 0.8, \"val\": 0.1}\n",
    "data = datasets.datasets(embs, np.array(labs), df, set_sizes, True)# takes 3 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84126/84126 [01:09<00:00, 1215.29it/s]\n",
      "100%|██████████| 4707/4707 [00:03<00:00, 1245.49it/s]\n",
      "100%|██████████| 4708/4708 [00:03<00:00, 1237.44it/s]\n",
      "100%|██████████| 84126/84126 [00:35<00:00, 2375.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class count for train: {'Knitwear': 5000, 'Shoes': 4088, 'Shorts': 1248, 'Trousers Denim': 2455, 'Under-, Nightwear': 5000, 'Socks and Tights': 1858, 'Dressed': 725, 'Accessories': 5000, 'Trousers': 5000, 'Skirts': 979, 'Shirts': 1705, 'Swimwear': 2213, 'Blouses': 4636, 'Jersey Basic': 5000, 'Outdoor': 3613, 'Dresses Ladies': 3880, 'Jersey Fancy': 5000, 'Dresses/Skirts girls': 1234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4707/4707 [00:01<00:00, 2357.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class count for val: {'Knitwear': 305, 'Shoes': 270, 'Shorts': 59, 'Trousers Denim': 139, 'Under-, Nightwear': 246, 'Socks and Tights': 62, 'Dressed': 49, 'Accessories': 651, 'Trousers': 303, 'Skirts': 68, 'Shirts': 91, 'Swimwear': 120, 'Blouses': 314, 'Jersey Basic': 177, 'Outdoor': 241, 'Dresses Ladies': 251, 'Jersey Fancy': 863, 'Dresses/Skirts girls': 84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4708/4708 [00:01<00:00, 2362.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final class count for test: {'Knitwear': 312, 'Shoes': 243, 'Shorts': 56, 'Trousers Denim': 146, 'Under-, Nightwear': 238, 'Socks and Tights': 69, 'Dressed': 57, 'Accessories': 631, 'Trousers': 266, 'Skirts': 67, 'Shirts': 71, 'Swimwear': 139, 'Blouses': 316, 'Jersey Basic': 180, 'Outdoor': 246, 'Dresses Ladies': 263, 'Jersey Fancy': 866, 'Dresses/Skirts girls': 77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58634/58634 [00:47<00:00, 1222.67it/s]\n",
      "100%|██████████| 4243/4243 [00:03<00:00, 1202.31it/s]\n",
      "100%|██████████| 4293/4293 [00:03<00:00, 1250.03it/s]\n"
     ]
    }
   ],
   "source": [
    "update()\n",
    "exclude_classes = ['Special Offers', 'Woven/Jersey/Knitted mix Baby','Unknown']\n",
    "dataloaders_imbalanced = datasets.get_dataloaders('garment_group_name', data, 5000, exclude_classes, 32)# look at Resource Utilization to see if capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BALANCED = False\n",
    "dataloaders = dataloaders_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fClfPP_3FRt",
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeD46C1cglRO"
   },
   "source": [
    "## Baseline\n",
    "\n",
    "The performance of the untuned CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMkglNVFexW4",
    "tags": []
   },
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoRA Train with specifc Parameters**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"lora-cap-5000_lora_model_120.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update()\n",
    "ranks = [0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 256]  # Only apply LoRA with rank 64 to the last layer\n",
    "\n",
    "#ranks = [256, 256, 256, 256, 256, 256, 256, 256,256, 256, 256, 256]  # Only apply LoRA with rank 64 to the last layer\n",
    "lr = 1e-03\n",
    "wd = 0.001\n",
    "epochs_num = 40\n",
    "lora_layers = []\n",
    "\n",
    "clip = {'m': copy.deepcopy(model), 'p': processor} # do not load each time\n",
    "lora_layers = model_functions.apply_lora_to_transformer(clip['m'].text_model.encoder.layers , lora_layers, ranks)\n",
    "lora_params_attention = model_functions.get_lora_params(clip['m'], print_layer = True)\n",
    "\n",
    "\n",
    "ft = training.FinetuneCLIP(dataloaders, clip, epochs = epochs_num )\n",
    "ft.conf = {'epochs': epochs_num, 'balanced':BALANCED}\n",
    "ft.model_prefix = \"lora-cap-5000-2-120-start\"\n",
    "\n",
    "# Initialize LoRA training with current hyperparameters\n",
    "ft.tt['soft'], ft.tt['LoRA'], ft.tt['image_fc'] = 0, 1 ,0 # Enable LoRA\n",
    "ft.initialize({'LoRA': lora_params_attention, 'lr': lr, 'weight_decay': wd, 'num_soft':0, 'add':''},\n",
    "              load=True, file_name=file_name)\n",
    "\n",
    "ft.count_parameters()\n",
    "all_predictions, all_labels, acc = ft.eval(False)\n",
    "\n",
    "# Train the model\n",
    "ft.es['pat']=10\n",
    "ft.train()\n",
    "\n",
    "# Evaluate the model\n",
    "all_predictions, all_labels, acc = ft.eval(False)\n",
    "utils.confussion_matrix(all_labels, all_predictions, list(dataloaders['test'].dataset.class_to_id.keys()), F1=False)\n",
    "ft.plot_loss_key('train')\n",
    "ft.plot_loss_key('val')\n",
    "\n",
    "print(f\"Accuracy for rank configuration {ranks} with lr={lr}, wd={wd} is {acc:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "ds-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
