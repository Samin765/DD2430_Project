{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2INOXSFL9vte",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "!pip install torch -q\n",
    "!pip install torchvision -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSDTu4h97TFF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# False if you have already created and saved a .pth file to PTH_SAVE_PATH\n",
    "CREATE_NEW_DATASET = True\n",
    "\n",
    "# train, test, val set size. Should sum to 1\n",
    "SET_SIZES = {\n",
    "    \"train\": 0.8,\n",
    "    \"test\": 0.1,\n",
    "    \"val\": 0.1,\n",
    "}\n",
    "\n",
    "# samples per class in uniform dataset\n",
    "N_SAMPLES = 400\n",
    "\n",
    "# path to dataset (do not change)\n",
    "HM_DATA_PATH = \"../dataset/\"\n",
    "\n",
    "# path to pth saves (do not change)\n",
    "PTH_SAVE_PATH = \"../pth/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpJXUgcT97sz"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPOBAjDlInvv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, random, importlib, transformers, itertools, copy\n",
    "import numpy as np, torch.nn as nn, torch, seaborn as sns, matplotlib.pyplot as plt, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "print(os.getcwd())# Our own files\n",
    "# sys.path.append('./src/')\n",
    "import model_functions, utils, training, datasets\n",
    "def set_seed(seed):# reproducable\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update():# if you change our files\n",
    "    import model_functions, utils, training, datasets\n",
    "    for lib in [model_functions, utils, training, datasets]:\n",
    "        importlib.reload(lib)# issues with not updating\n",
    "update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou5QvXmt3_Kr",
    "outputId": "ee73a633-1d13-47ed-86e3-640c1a03e48d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available(): # For apple silicon\n",
    "    device = 'mps'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = transformers.CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = transformers.CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor.feature_extractor.do_rescale = False # make sure image values: False=> [0-1] and True=> [0,255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdQe6TDNGX4K",
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Full dataset, run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_name = 'garment_group_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(HM_DATA_PATH+'articles_filtered.csv')\n",
    "embs = torch.load(HM_DATA_PATH+'embedds.pth', weights_only=True) # all 100k embeddings\n",
    "labs = torch.load(HM_DATA_PATH+'labels.pth', weights_only=True).tolist() #  100k labels\n",
    "hmd = datasets.HMDatasetDuplicates(embs, np.array(labs), df)\n",
    "print(hmd.article_id2suclass(694805002, column_name))\n",
    "print(len(labs))\n",
    "BALANCED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update()\n",
    "set_sizes = {\"train\": 0.8, \"val\": 0.1}\n",
    "data = datasets.datasets(embs, np.array(labs), df, set_sizes, True)# takes 3 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_classes = [\n",
    "    \"Unknown\",\n",
    "    \"Special Offers\",\n",
    "    \"Woven/Jersey/Knitted mix Baby\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update()\n",
    "dataloaders_imbalanced = datasets.get_dataloaders(column_name, data, 5000, exclude_classes, 324)# look at Resource Utilization to see if capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BALANCED = False\n",
    "dataloaders = dataloaders_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMkglNVFexW4",
    "tags": []
   },
   "source": [
    "## LoRA experiments on garment_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"lora-cap-5000-2-120-start_lora.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lora, unweighed, no hard mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_lora(weighted, hard_mining, fc=False):\n",
    "    update()\n",
    "\n",
    "    ranks = [0, 0, 0, 0, 0, 0,0, 0,0, 0, 256, 256]  # Only apply LoRA with rank 64 to the last layer\n",
    "\n",
    "    #ranks = [256, 256, 256, 256, 256, 256, 256, 256,256, 256, 256, 256]  # Only apply LoRA with rank 64 to the last layer\n",
    "    lr = 1e-04\n",
    "    wd = 0.001\n",
    "    epochs_num = 100\n",
    "    lora_layers = []\n",
    "\n",
    "    clip = {'m': copy.deepcopy(model), 'p': processor} # do not load each time\n",
    "    lora_layers = model_functions.apply_lora_to_transformer(clip['m'].text_model.encoder.layers , lora_layers, ranks)\n",
    "    lora_params_attention = model_functions.get_lora_params(clip['m'], print_layer = True)\n",
    "\n",
    "\n",
    "    ft = training.FinetuneCLIP(dataloaders, clip, epochs = epochs_num )\n",
    "    ft.conf = {'epochs': epochs_num, 'balanced':BALANCED}\n",
    "    ft.model_prefix = f\"draft-experiments/weighted={weighted}_hard-mining={hard_mining}_fc={fc}\"\n",
    "    ft.hard_mining = hard_mining\n",
    "    ft.weighted = weighted\n",
    "\n",
    "    # Initialize LoRA training with current hyperparameters\n",
    "    ft.tt['soft'], ft.tt['LoRA'], ft.tt['image_fc'] = 0, 1, 0 # Enable LoRA\n",
    "    if fc:\n",
    "        ft.tt['image_fc'] = 1\n",
    "\n",
    "\n",
    "    ft.initialize({'LoRA': lora_params_attention, 'lr': lr, 'weight_decay': wd, 'num_soft':0, 'add':''},\n",
    "                load=False, file_name=file_name)\n",
    "\n",
    "\n",
    "    ft.count_parameters()\n",
    "    #all_predictions, all_labels, acc = ft.eval(False)\n",
    "\n",
    "    # Train the model\n",
    "    ft.es['pat']=30\n",
    "    ft.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    all_predictions, all_labels, acc = ft.eval(False)\n",
    "    utils.confussion_matrix(all_labels, all_predictions, list(dataloaders['test'].dataset.class_to_id.keys()), F1=False)\n",
    "    ft.plot_loss_key('train', 'final')\n",
    "    ft.plot_loss_key('val', 'final')\n",
    "\n",
    "    print(f\"Accuracy for \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weighted in [True, False]:\n",
    "    for hard_mining in [True, False]:\n",
    "        run_lora(weighted, hard_mining)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
